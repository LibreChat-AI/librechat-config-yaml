version: 1.1.6

cache: true

registration:
  socialLogins: ["discord", "facebook", "github", "google", "openid"]

endpoints:
  custom:
    # Anyscale
    # # Model list: https://console.anyscale.com/v2/playground
    - name: "Anyscale"
      apiKey: "${ANYSCALE_API_KEY}"
      baseURL: "https://api.endpoints.anyscale.com/v1"
      models:
        default: [
          "meta-llama/Llama-2-7b-chat-hf",
          "meta-llama/Llama-2-13b-chat-hf",
          "meta-llama/Llama-2-70b-chat-hf",
          "codellama/CodeLlama-34b-Instruct-hf",
          "codellama/CodeLlama-70b-Instruct-hf",
          "mistralai/Mistral-7B-Instruct-v0.1",
          "mistralai/Mixtral-8x7B-Instruct-v0.1",
          "mlabonne/NeuralHermes-2.5-Mistral-7B",
          "Open-Orca/Mistral-7B-OpenOrca",
          "HuggingFaceH4/zephyr-7b-beta",
          "google/gemma-7b-it"
          ]
        fetch: false
      titleConvo: true
      titleModel: "meta-llama/Llama-2-7b-chat-hf"
      summarize: false
      summaryModel: "meta-llama/Llama-2-7b-chat-hf"
      forcePrompt: false
      modelDisplayLabel: "Anyscale"

    # APIpie
    # https://apipie.ai/dashboard/
    # Script to fetch models: https://github.com/LibreChat-AI/librechat-config-yaml/blob/main/scripts/apipie.py
    - name: "APIpie"
      apiKey: "${APIPIE_API_KEY}"
      baseURL: "https://apipie.ai/v1/"
      models:
        default: [
          "DeepSeek-V3",
          "Llama-2-13b-chat-hf",
          "Llama-2-70b-chat-hf",
          "Llama-2-70b-hf",
          "Llama-2-7b-chat-hf",
          "Llama-3-70b-chat-hf",
          "Llama-3-8b-chat-hf",
          "Llama-3.1-Nemotron-70B-Instruct-HF",
          "Llama-3.2-11B-Vision-Instruct-Turbo",
          "Llama-3.2-3B-Instruct-Turbo",
          "Llama-3.2-90B-Vision-Instruct-Turbo",
          "Llama-3.3-70B-Instruct-Turbo",
          "Llama-Rank-V1",
          "Meta-Llama-3-70B-Instruct",
          "Meta-Llama-3-70B-Instruct-Lite",
          "Meta-Llama-3-70B-Instruct-Turbo",
          "Meta-Llama-3-8B-Instruct",
          "Meta-Llama-3-8B-Instruct-Lite",
          "Meta-Llama-3-8B-Instruct-Turbo",
          "Meta-Llama-3.1-405B-Instruct-Turbo",
          "Meta-Llama-3.1-70B-Instruct-Turbo",
          "Meta-Llama-3.1-8B-Instruct-Turbo",
          "Meta-Llama-3.1-8B-Instruct-Turbo-128K",
          "Mistral-7B-Instruct-v0.1",
          "Mistral-7B-Instruct-v0.2",
          "Mistral-7B-Instruct-v0.3",
          "Mistral-7B-v0.1",
          "Mixtral-8x22B-Instruct-v0.1",
          "Mixtral-8x22B-v0.1",
          "Mixtral-8x7B-Instruct-v0.1",
          "Mixtral-8x7B-v0.1",
          "MythoMax-L2-13b",
          "MythoMax-L2-13b-Lite",
          "Nous-Hermes-2-Mixtral-8x7B-DPO",
          "QwQ-32B-Preview",
          "Qwen2-72B-Instruct",
          "Qwen2-VL-72B-Instruct",
          "Qwen2.5-72B-Instruct-Turbo",
          "Qwen2.5-7B-Instruct-Turbo",
          "SOLAR-10.7B-Instruct-v1.0",
          "WizardLM-2-7B",
          "WizardLM-2-8x22B",
          "airoboros-70b",
          "airoboros-l2-70b",
          "anthropic.claude-3-5-sonnet-20240620-v1:0",
          "chatgpt-4o-latest",
          "chatx_cheap_128k",
          "chatx_cheap_32k",
          "chatx_cheap_4k",
          "chatx_cheap_64k",
          "chatx_cheap_8k",
          "chatx_mids_4k",
          "chatx_premium_128k",
          "chatx_premium_32k",
          "chatx_premium_4k",
          "chatx_premium_8k",
          "chronos-hermes-13b-v2",
          "claude-2",
          "claude-2.0",
          "claude-2.1",
          "claude-3-5-haiku",
          "claude-3-5-haiku-20241022",
          "claude-3-5-haiku-20241022-v1",
          "claude-3-5-haiku-latest",
          "claude-3-5-sonnet",
          "claude-3-5-sonnet-20240620",
          "claude-3-5-sonnet-20240620-v1",
          "claude-3-5-sonnet-20240620-v1:0",
          "claude-3-5-sonnet-20241022",
          "claude-3-5-sonnet-20241022-v2",
          "claude-3-5-sonnet-latest",
          "claude-3-haiku-20240307",
          "claude-3-opus",
          "claude-3-opus-20240229",
          "claude-3-opus-20240229-v1",
          "claude-3-opus-latest",
          "claude-3.5-haiku",
          "claude-3.5-haiku-20241022",
          "claude-instant-v1",
          "claude-v2",
          "claude-v2:1",
          "claude2",
          "command",
          "command-light",
          "command-light-nightly",
          "command-light-text-v14",
          "command-nightly",
          "command-r",
          "command-r-03-2024",
          "command-r-08-2024",
          "command-r-plus",
          "command-r-plus-04-2024",
          "command-r-plus-08-2024",
          "command-r-plus-v1",
          "command-r-v1",
          "command-r7b-12-2024",
          "command-text-v14",
          "dbrx-instruct",
          "deepseek-chat",
          "deepseek-chat-v2.5",
          "deepseek-llm-67b-chat",
          "dolphin-2.6-mixtral-8x7b",
          "dolphin-mixtral-8x22b",
          "dolphin-mixtral-8x7b",
          "eva-llama-3.33-70b",
          "eva-qwen-2.5-32b",
          "eva-qwen-2.5-72b",
          "gemini-1.5-flash",
          "gemini-1.5-flash-8b",
          "gemini-1.5-flash-latest",
          "gemini-1.5-pro",
          "gemini-1.5-pro-exp-0801",
          "gemini-1.5-pro-exp-0827",
          "gemini-1.5-pro-latest",
          "gemini-flash",
          "gemini-flash-1.5",
          "gemini-flash-1.5-8b",
          "gemini-pro",
          "gemini-pro-1.5",
          "gemini-pro-vision",
          "gemma-1.1-7b-it",
          "gemma-2-27b-it",
          "gemma-2-9b-it",
          "gemma-2b-it",
          "gemma-7b-it",
          "general",
          "goliath-120b",
          "gpt-3.5",
          "gpt-3.5-turbo",
          "gpt-3.5-turbo-0125",
          "gpt-3.5-turbo-0613",
          "gpt-3.5-turbo-1106",
          "gpt-3.5-turbo-16k",
          "gpt-3.5-turbo-instruct",
          "gpt-4",
          "gpt-4-0125-preview",
          "gpt-4-0314",
          "gpt-4-0613",
          "gpt-4-1106-preview",
          "gpt-4-1106-vision-preview",
          "gpt-4-32k",
          "gpt-4-32k-0314",
          "gpt-4-turbo",
          "gpt-4-turbo-2024-04-09",
          "gpt-4-turbo-preview",
          "gpt-4-vision-preview",
          "gpt-4o",
          "gpt-4o-2024-05-13",
          "gpt-4o-2024-08-06",
          "gpt-4o-2024-11-20",
          "gpt-4o-audio-preview",
          "gpt-4o-audio-preview-2024-10-01",
          "gpt-4o-audio-preview-2024-12-17",
          "gpt-4o-mini",
          "gpt-4o-mini-2024-07-18",
          "gpt-4o-mini-audio-preview",
          "gpt-4o-mini-audio-preview-2024-12-17",
          "grok-2-1212",
          "grok-2-vision-1212",
          "grok-beta",
          "grok-vision-beta",
          "hermes-2-pro-llama-3-8b",
          "hermes-3-llama-3.1-405b",
          "hermes-3-llama-3.1-70b",
          "inflection-3-pi",
          "j2-grande-instruct",
          "j2-jumbo-instruct",
          "j2-mid",
          "j2-mid-v1",
          "j2-ultra",
          "j2-ultra-v1",
          "jamba-1-5-large",
          "jamba-1-5-large-v1",
          "jamba-1-5-mini",
          "jamba-1-5-mini-v1",
          "jamba-instruct",
          "jamba-instruct-v1",
          "l3-euryale-70b",
          "l3-lunaris-8b",
          "l3.1-70b-hanami-x1",
          "l3.1-euryale-70b",
          "l3.3-euryale-70b",
          "large-latest",
          "lfm-40b",
          "llama-2-13b-chat",
          "llama-3-70b-instruct",
          "llama-3-8b-instruct",
          "llama-3-lumimaid-70b",
          "llama-3-lumimaid-8b",
          "llama-3-sonar-large-32k-chat",
          "llama-3.1-405b",
          "llama-3.1-405b-instruct",
          "llama-3.1-70b-instruct",
          "llama-3.1-8b-instruct",
          "llama-3.1-lumimaid-70b",
          "llama-3.1-lumimaid-8b",
          "llama-3.1-nemotron-70b-instruct",
          "llama-3.1-sonar-huge-128k-online",
          "llama-3.1-sonar-large-128k-chat",
          "llama-3.1-sonar-large-128k-online",
          "llama-3.1-sonar-small-128k-chat",
          "llama-3.1-sonar-small-128k-online",
          "llama-3.2-11b-vision-instruct",
          "llama-3.2-1b-instruct",
          "llama-3.2-3b-instruct",
          "llama-3.2-90b-vision-instruct",
          "llama-3.3-70b-instruct",
          "llama-guard-2-8b",
          "llama2-13b-chat-v1",
          "llama2-70b-chat-v1",
          "llama3-1",
          "llama3-1-405b-instruct-v1:0",
          "llama3-1-70b-instruct-v1",
          "llama3-1-70b-instruct-v1:0",
          "llama3-1-8b-instruct-v1",
          "llama3-1-8b-instruct-v1:0",
          "llama3-2",
          "llama3-2-11b-instruct-v1",
          "llama3-2-1b-instruct-v1",
          "llama3-2-3b-instruct-v1",
          "llama3-2-90b-instruct-v1",
          "llama3-3-70b-instruct-v1",
          "llama3-70b-instruct-v1",
          "llama3-70b-instruct-v1:0",
          "llama3-8b-instruct-v1",
          "llama3-8b-instruct-v1:0",
          "magnum-72b",
          "magnum-v2-72b",
          "magnum-v4-72b",
          "medium",
          "meta-llama-3.1-8b-instruct",
          "midnight-rose-70b",
          "ministral-3b",
          "ministral-3b-latest",
          "ministral-8b",
          "ministral-8b-latest",
          "mistral",
          "mistral-7b-instruct",
          "mistral-7b-instruct-v0",
          "mistral-7b-instruct-v0.1",
          "mistral-7b-instruct-v0.3",
          "mistral-large",
          "mistral-large-2402-v1",
          "mistral-large-2407",
          "mistral-large-2411",
          "mistral-large-latest",
          "mistral-medium",
          "mistral-nemo",
          "mistral-small",
          "mistral-small-2402-v1",
          "mistral-small-latest",
          "mistral-tiny",
          "mixtral",
          "mixtral-8x22b-instruct",
          "mixtral-8x7b",
          "mixtral-8x7b-instruct",
          "mixtral-8x7b-instruct-v0",
          "mn-celeste-12b",
          "mn-inferor-12b",
          "mn-starcannon-12b",
          "mythalion-13b",
          "mythomax-l2-13b",
          "nai-meta-v1",
          "noromaid-20b",
          "nous-hermes-2-mixtral-8x7b-dpo",
          "nous-hermes-2-vision-7b",
          "nous-hermes-llama2-13b",
          "nova-canvas-v1",
          "nova-lite-v1",
          "nova-micro-v1",
          "nova-pro-v1",
          "nova-reel-v1",
          "o1",
          "o1-2024-12-17",
          "o1-mini",
          "o1-mini-2024-09-12",
          "o1-preview",
          "o1-preview-2024-09-12",
          "olympus-premier-v1",
          "online-llama",
          "openchat-7b",
          "openchat_3.5",
          "openhermes-2.5-mistral-7b",
          "palm-2-chat-bison",
          "palm-2-chat-bison-32k",
          "phi-3-medium-128k-instruct",
          "phi-3-mini-128k-instruct",
          "phi-3.5-mini-128k-instruct",
          "phi-4",
          "pixtral-12b",
          "pixtral-large-2411",
          "qvq-72b-preview",
          "qwen-2-72b-instruct",
          "qwen-2-7b-instruct",
          "qwen-2-vl-72b-instruct",
          "qwen-2-vl-7b-instruct",
          "qwen-2.5-72b-instruct",
          "qwen-2.5-7b-instruct",
          "qwen1-5",
          "qwen2",
          "qwq-32b-preview",
          "remm-slerp-l2-13b",
          "rocinante-12b",
          "scb10x-llama3-typhoon-v1-5-8b-instruct",
          "scb10x-llama3-typhoon-v1-5x-4f316",
          "small",
          "sorcererlm-8x22b",
          "tiny",
          "titan",
          "titan-text-express-v1",
          "titan-text-lite-v1",
          "titan-text-premier-v1",
          "titan-tg1-large",
          "toppy-m-7b",
          "unslopnemo-12b",
          "weaver",
          "wizardlm-2-7b",
          "wizardlm-2-8x22b",
          "xwin-lm-70b",
          "yi-large",
          "yi-vision",
          "zephyr-orpo-141b-A35b-v0.1"
          ]
        fetch: false
      titleConvo: true
      titleModel: "claude-3-haiku"
      summarize: false
      summaryModel: "claude-3-haiku"
      dropParams: ["stream"]
      modelDisplayLabel: "APIpie"
      iconURL: "https://raw.githubusercontent.com/fuegovic/lc-config-yaml/main/icons/APIpie.png"
 
    # cohere
    # Model list: https://dashboard.cohere.com/playground/chat
    - name: "cohere"
      apiKey: "${COHERE_API_KEY}"
      baseURL: "https://api.cohere.ai/v1"
      models:
        default: [
          "c4ai-aya-23-35b",
          "c4ai-aya-23-8b",
          "command",
          "command-light",
          "command-light-nightly",
          "command-nightly",
          "command-r",
          "command-r-plus",
          ]
        fetch: false
      modelDisplayLabel: "cohere"
      titleModel: "command"
      dropParams: ["stop", "user", "frequency_penalty", "presence_penalty", "temperature", "top_p"]

    # DEEPNIGHT
    # https://github.com/brahmai-research/aiforcause
    # Model list: https://aiforcause.deepnight.tech/models
    - name: "DEEPNIGHT"
      apiKey: "sk-free1234"
      baseURL: "https://aiforcause.deepnight.tech/openai/"
      models:
        default: [
          "gpt-35-turbo",
          "gpt-35-turbo-16k",
          "gpt-4-turbo"
          ]
        fetch: false
      titleConvo: true
      titleModel: "gpt-35-turbo"
      summarize: false
      summaryModel: "gpt-35-turbo"
      forcePrompt: false
      modelDisplayLabel: "DEEPNIGHT"
      addParams:
        stream: True
      iconURL: "https://raw.githubusercontent.com/fuegovic/lc-config-yaml/main/icons/DEEPNIGHT.png"

    # deepseek
    # https://platform.deepseek.com/api_keys
    # Model list: https://platform.deepseek.com/api-docs/pricing
    - name: "deepseek"
      apiKey: "${DEEPSEEK_API_KEY}"
      baseURL: "https://api.deepseek.com"
      models:
        default: [
          "deepseek-chat",
          "deepseek-coder",
          "deepseek-reasoner",
          ]
        fetch: false
      titleConvo: true
      titleModel: "deepseek-chat"
      summarize: false
      summaryModel: "deepseek-chat"
      modelDisplayLabel: "DeepSeek"

    # Fireworks.ai
    # Models: https://fireworks.ai/models?show=Serverless
    - name: "Fireworks"
      apiKey: "${FIREWORKS_API_KEY}"
      baseURL: "https://api.fireworks.ai/inference/v1"
      models:
        default: [
          "accounts/fireworks/models/devashisht-test-v2",
          "accounts/fireworks/models/dt-fc-rc-v1",
          "accounts/fireworks/models/firefunction-v1",
          "accounts/fireworks/models/firefunction-v2",
          "accounts/fireworks/models/firellava-13b",
          "accounts/devashisht-72fdad/models/function-calling-v11",
          "accounts/fireworks/models/fw-function-call-34b-v0",
          "accounts/stability/models/japanese-stablelm-instruct-beta-70b",
          "accounts/stability/models/japanese-stablelm-instruct-gamma-7b",
          "accounts/fireworks/models/japanese-stable-vlm",
          "accounts/fireworks/models/gemma2-9b-it",
          "accounts/fireworks/models/llama-v3p1-405b-instruct",
          "accounts/fireworks/models/llama-v3p1-70b-instruct",
          "accounts/fireworks/models/llama-v3p1-8b-instruct",
          "accounts/fireworks/models/llama-v3-70b-instruct",
          "accounts/fireworks/models/llama-v3-70b-instruct-hf",
          "accounts/fireworks/models/llama-v3-8b-hf",
          "accounts/fireworks/models/llama-v3-8b-instruct",
          "accounts/fireworks/models/llama-v3-8b-instruct-hf",
          "accounts/fireworks/models/llama-v2-13b-chat",
          "accounts/fireworks/models/llama-v2-13b-code-instruct",
          "accounts/fireworks/models/llama-v2-34b-code-instruct",
          "accounts/fireworks/models/llama-v2-70b-chat",
          "accounts/fireworks/models/llama-v2-70b-code-instruct",
          "accounts/fireworks/models/llama-v2-7b-chat",
          "accounts/fireworks/models/deepseek-coder-v2-instruct",
          "accounts/fireworks/models/deepseek-coder-v2-lite-instruct",
          "accounts/fireworks/models/llava-v15-13b-fireworks",
          "accounts/fireworks/models/mistral-7b-instruct-4k",
          "accounts/dev-e24710/models/mistral-spellbound-format",
          "accounts/fireworks/models/mixtral-8x22b-instruct",
          "accounts/fireworks/models/mixtral-8x7b-instruct",
          "accounts/fireworks/models/mixtral-8x7b-instruct-hf",
          "accounts/fireworks/models/new-mixtral-chat",
          "accounts/fireworks/models/qwen-14b-chat",
          "accounts/fireworks/models/qwen-1-8b-chat",
          "accounts/fireworks/models/qwen-72b-chat",
          "accounts/stability/models/stablelm-zephyr-3b",
          "accounts/fireworks/models/yi-34b-200k-capybara",
          ]
        fetch: false
      titleConvo: true
      titleModel: "accounts/fireworks/models/llama-v2-7b-chat"
      summarize: false
      summaryModel: "accounts/fireworks/models/llama-v2-7b-chat"
      forcePrompt: false
      modelDisplayLabel: "Fireworks"
      dropParams: ["user"]

    # GitHub 
    - name: "Github Models"
      iconURL: https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png
      apiKey: "${GITHUB_TOKEN}"
      baseURL: "https://models.inference.ai.azure.com"
      models:
        default: [
          "gpt-4o", 
          "gpt-4o-mini", 
          "o1", 
          "o1-mini", 
          "o1-preview", 
          "Llama-3.3-70B-Instruct", 
          "Llama-3.2-90B-Vision-Instruct", 
          "Llama-3.2-11B-Vision-Instruct", 
          "Meta-Llama-3.1-405B-Instruct", 
          "Meta-Llama-3.1-70B-Instruct", 
          "Meta-Llama-3.1-8B-Instruct", 
          "Phi-4", 
          "Phi-3.5-MoE-instruct",
          "Phi-3.5-mini-instruct",
          "Phi-3.5-vision-instruct",
          "Ministral-3B", 
          "Codestral-2501", 
          "Mistral-large-2407", 
          "Mistral-large", 
          "Mistral-small", 
          "Cohere-command-r-plus-08-2024", 
          "Cohere-command-r-08-2024", 
          "AI21-Jamba-1.5-Large", 
          "AI21-Jamba-1.5-Mini"
          ]
        fetch: false
      titleConvo: true
      titleModel: "gpt-4o-mini"

    # groq
    # Model list: https://console.groq.com/settings/limits
    - name: "groq"
      apiKey: "${GROQ_API_KEY}"
      baseURL: "https://api.groq.com/openai/v1/"
      models:
        default: [
          "gemma2-9b-it",
          "gemma-7b-it",
          "llama-3.1-8b-instant",
          "llama3-groq-70b-8192-tool-use-preview",
          "llama3-groq-8b-8192-tool-use-preview",
          "llama-3.1-70b-versatile",
          "llama-3.1-70b-specdec",
          "llama-3.1-8b-instant",
          "llama-3.2-1b-preview",
          "llama-3.2-3b-preview",
          "llama-3.2-11b-vision-preview",
          "llama-3.2-90b-vision-preview",
          "llama3-70b-8192",
          "llama3-8b-8192",
          "mixtral-8x7b-32768",
          ]
        fetch: false
      titleConvo: true
      titleModel: "mixtral-8x7b-32768"
      modelDisplayLabel: "groq"

    # HuggingFace
    # https://huggingface.co/settings/tokens
    - name: 'HuggingFace'
      apiKey: '${HUGGINGFACE_TOKEN}'
      baseURL: 'https://api-inference.huggingface.co/v1'
      models:
        default: [
          "codellama/CodeLlama-34b-Instruct-hf",
          "google/gemma-1.1-2b-it",
          "google/gemma-1.1-7b-it",
          "HuggingFaceH4/starchat2-15b-v0.1",
          "HuggingFaceH4/zephyr-7b-beta",
          "meta-llama/Meta-Llama-3-8B-Instruct",
          "microsoft/Phi-3-mini-4k-instruct",
          "mistralai/Mistral-7B-Instruct-v0.1",
          "mistralai/Mistral-7B-Instruct-v0.2",
          "mistralai/Mixtral-8x7B-Instruct-v0.1",
          "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO",
          ]
        fetch: true
      titleConvo: true
      titleModel: "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO"
      dropParams: ["top_p"]

    # Hyperbolic
    # https://app.hyperbolic.xyz/models
    - name: 'Hyperbolic'
      apiKey: '${HYPERBOLIC_API_KEY}'
      baseURL: 'https://api.hyperbolic.xyz/v1/'
      models:
        default: [
          "deepseek-ai/DeepSeek-V2.5",
          "meta-llama/Llama-3.2-3B-Instruct",
          "meta-llama/Meta-Llama-3-70B-Instruct",
          "meta-llama/Meta-Llama-3.1-405B",
          "meta-llama/Meta-Llama-3.1-405B-FP8",
          "meta-llama/Meta-Llama-3.1-405B-Instruct",
          "meta-llama/Meta-Llama-3.1-70B-Instruct",
          "meta-llama/Meta-Llama-3.1-8B-Instruct",
          "NousResearch/Hermes-3-Llama-3.1-70B",
          "Qwen/Qwen2.5-Coder-32B-Instruct",
          "Qwen/Qwen2.5-72B-Instruct",
          ]
        fetch: false
      titleConvo: true
      titleModel: "meta-llama/Meta-Llama-3.1-8B-Instruct"
      modelDisplayLabel: "Hyperbolic"
      iconURL: "https://pbs.twimg.com/profile_images/1775708849707819008/1RRWsmmg_400x400.jpg"

    # kluster.ai
    # https://platform.kluster.ai/apikeys
    - name: "Kluster"
      apiKey: "${KLUSTER_API_KEY}"
      baseURL: "https://api.kluster.ai/v1/"
      models:
        default: [
          "deepseek-ai/DeepSeek-R1",
          "klusterai/Meta-Llama-3.1-405B-Instruct-Turbo",
          "klusterai/Meta-Llama-3.1-8B-Instruct-Turbo",
          "klusterai/Meta-Llama-3.3-70B-Instruct-Turbo",
          ]
        fetch: false
      titleConvo: true
      titleModel: 'klusterai/Meta-Llama-3.1-8B-Instruct-Turbo'
      modelDisplayLabel: 'Kluster'
      iconURL: "https://platform.kluster.ai/cropped-fav-1-144x144.png"

    # Mistral AI API
    # Model list: https://docs.mistral.ai/getting-started/models/
    - name: "Mistral"
      apiKey: "${MISTRAL_API_KEY}"
      baseURL: "https://api.mistral.ai/v1"
      models: 
        default: [
          "mistral-large-latest",
          "pixtral-large-latest",
          "ministral-3b-latest",
          "ministral-8b-latest",
          "mistral-small-latest",
          "codestral-latest",
          "pixtral-12b-2409",
          "open-mistral-nemo",
          "open-codestral-mamba",
          "open-mistral-7b",
          "open-mixtral-8x7b",
          "open-mixtral-8x22b"
          ]
        fetch: false
      titleConvo: true
      titleMethod: "completion"
      titleModel: "mistral-tiny"
      summarize: false
      summaryModel: "mistral-tiny"
      forcePrompt: false
      modelDisplayLabel: "Mistral"
      dropParams: ["stop", "user", "frequency_penalty", "presence_penalty"]

    # NVIDIA         
    # https://build.nvidia.com/explore/discover
    - name: "Nvidia"
      apiKey: "${NVIDIA_API_KEY}"
      baseURL: "https://integrate.api.nvidia.com/v1/"
      models:
        default: [
          "nvidia/llama-3.1-nemotron-51b-instruct",
          "nvidia/llama-3.1-nemotron-70b-instruct",
          "nvidia/nemotron-mini-4b-instruct",
          "nvidia/nemotron-4-340b-instruct",
          ]
        fetch: false
      titleConvo: true
      titleModel: "nvidia/nemotron-mini-4b-instruct"
      modelDisplayLabel: "Nvidia"
      iconURL: "https://raw.githubusercontent.com/LibreChat-AI/librechat-config-yaml/refs/heads/main/icons/nvidia.png"

    # OpenRouter.ai
    # Model list: https://openrouter.ai/models
    # Script to fetch models: https://github.com/LibreChat-AI/librechat-config-yaml/blob/main/scripts/openrouter.py
    - name: "OpenRouter"
      apiKey: "${OPENROUTER_KEY}"
      baseURL: "https://openrouter.ai/api/v1"
      models:
        default: [
          "openrouter/auto",
          "---FREE---",
          "deepseek/deepseek-r1:free",
          "google/gemini-2.0-flash-exp:free",
          "google/gemini-2.0-flash-thinking-exp-1219:free",
          "google/gemini-2.0-flash-thinking-exp:free",
          "google/gemini-exp-1114:free",
          "google/gemini-exp-1121:free",
          "google/gemini-exp-1206:free",
          "google/gemma-2-9b-it:free",
          "google/learnlm-1.5-pro-experimental:free",
          "gryphe/mythomax-l2-13b:free",
          "huggingfaceh4/zephyr-7b-beta:free",
          "meta-llama/llama-3-8b-instruct:free",
          "meta-llama/llama-3.1-405b-instruct:free",
          "meta-llama/llama-3.1-70b-instruct:free",
          "meta-llama/llama-3.1-8b-instruct:free",
          "meta-llama/llama-3.2-11b-vision-instruct:free",
          "meta-llama/llama-3.2-1b-instruct:free",
          "meta-llama/llama-3.2-3b-instruct:free",
          "meta-llama/llama-3.2-90b-vision-instruct:free",
          "microsoft/phi-3-medium-128k-instruct:free",
          "microsoft/phi-3-mini-128k-instruct:free",
          "mistralai/mistral-7b-instruct:free",
          "openchat/openchat-7b:free",
          "qwen/qwen-2-7b-instruct:free",
          "sophosympatheia/rogue-rose-103b-v0.2:free",
          "undi95/toppy-m-7b:free",
          "---NITRO---",
          "gryphe/mythomax-l2-13b:nitro",
          "meta-llama/llama-3-70b-instruct:nitro",
          "meta-llama/llama-3-8b-instruct:nitro",
          "meta-llama/llama-3.1-405b-instruct:nitro",
          "meta-llama/llama-3.1-70b-instruct:nitro",
          "mistralai/mistral-7b-instruct:nitro",
          "mistralai/mixtral-8x7b-instruct:nitro",
          "undi95/toppy-m-7b:nitro",
          "---BETA---",
          "anthropic/claude-2.0:beta",
          "anthropic/claude-2.1:beta",
          "anthropic/claude-2:beta",
          "anthropic/claude-3-haiku:beta",
          "anthropic/claude-3-opus:beta",
          "anthropic/claude-3-sonnet:beta",
          "anthropic/claude-3.5-haiku-20241022:beta",
          "anthropic/claude-3.5-haiku:beta",
          "anthropic/claude-3.5-sonnet-20240620:beta",
          "anthropic/claude-3.5-sonnet:beta",
          "---EXTENDED---",
          "gryphe/mythomax-l2-13b:extended",
          "meta-llama/llama-3-8b-instruct:extended",
          "neversleep/llama-3-lumimaid-8b:extended",
          "openai/gpt-4o:extended",
          "undi95/remm-slerp-l2-13b:extended",
          "---AI21---",
          "ai21/jamba-1-5-large",
          "ai21/jamba-1-5-mini",
          "ai21/jamba-instruct",
          "---AMAZON---",
          "amazon/nova-lite-v1",
          "amazon/nova-micro-v1",
          "amazon/nova-pro-v1",
          "---ANTHROPIC---",
          "anthropic/claude-2",
          "anthropic/claude-2.0",
          "anthropic/claude-2.1",
          "anthropic/claude-3-haiku",
          "anthropic/claude-3-opus",
          "anthropic/claude-3-sonnet",
          "anthropic/claude-3.5-haiku",
          "anthropic/claude-3.5-haiku-20241022",
          "anthropic/claude-3.5-sonnet",
          "anthropic/claude-3.5-sonnet-20240620",
          "---COHERE---",
          "cohere/command",
          "cohere/command-r",
          "cohere/command-r-03-2024",
          "cohere/command-r-08-2024",
          "cohere/command-r-plus",
          "cohere/command-r-plus-04-2024",
          "cohere/command-r-plus-08-2024",
          "cohere/command-r7b-12-2024",
          "---DEEPSEEK---",
          "deepseek/deepseek-chat",
          "deepseek/deepseek-chat-v2.5",
          "deepseek/deepseek-r1",
          "deepseek/deepseek-r1-distill-llama-70b",
          "---EVA-UNIT-01---",
          "eva-unit-01/eva-llama-3.33-70b",
          "eva-unit-01/eva-qwen-2.5-32b",
          "eva-unit-01/eva-qwen-2.5-72b",
          "---GOOGLE---",
          "google/gemini-flash-1.5",
          "google/gemini-flash-1.5-8b",
          "google/gemini-flash-1.5-8b-exp",
          "google/gemini-flash-1.5-exp",
          "google/gemini-pro",
          "google/gemini-pro-1.5",
          "google/gemini-pro-1.5-exp",
          "google/gemini-pro-vision",
          "google/gemma-2-27b-it",
          "google/gemma-2-9b-it",
          "google/palm-2-chat-bison",
          "google/palm-2-chat-bison-32k",
          "google/palm-2-codechat-bison",
          "google/palm-2-codechat-bison-32k",
          "---LIQUID---",
          "liquid/lfm-3b",
          "liquid/lfm-40b",
          "liquid/lfm-7b",
          "---META-LLAMA---",
          "meta-llama/llama-2-13b-chat",
          "meta-llama/llama-2-70b-chat",
          "meta-llama/llama-3-70b-instruct",
          "meta-llama/llama-3-8b-instruct",
          "meta-llama/llama-3.1-405b",
          "meta-llama/llama-3.1-405b-instruct",
          "meta-llama/llama-3.1-70b-instruct",
          "meta-llama/llama-3.1-8b-instruct",
          "meta-llama/llama-3.2-11b-vision-instruct",
          "meta-llama/llama-3.2-1b-instruct",
          "meta-llama/llama-3.2-3b-instruct",
          "meta-llama/llama-3.2-90b-vision-instruct",
          "meta-llama/llama-3.3-70b-instruct",
          "meta-llama/llama-guard-2-8b",
          "---MICROSOFT---",
          "microsoft/phi-3-medium-128k-instruct",
          "microsoft/phi-3-mini-128k-instruct",
          "microsoft/phi-3.5-mini-128k-instruct",
          "microsoft/phi-4",
          "microsoft/wizardlm-2-7b",
          "microsoft/wizardlm-2-8x22b",
          "---MISTRALAI---",
          "mistralai/codestral-2501",
          "mistralai/codestral-mamba",
          "mistralai/ministral-3b",
          "mistralai/ministral-8b",
          "mistralai/mistral-7b-instruct",
          "mistralai/mistral-7b-instruct-v0.1",
          "mistralai/mistral-7b-instruct-v0.3",
          "mistralai/mistral-large",
          "mistralai/mistral-large-2407",
          "mistralai/mistral-large-2411",
          "mistralai/mistral-medium",
          "mistralai/mistral-nemo",
          "mistralai/mistral-small",
          "mistralai/mistral-tiny",
          "mistralai/mixtral-8x22b-instruct",
          "mistralai/mixtral-8x7b",
          "mistralai/mixtral-8x7b-instruct",
          "mistralai/pixtral-12b",
          "mistralai/pixtral-large-2411",
          "---NEVERSLEEP---",
          "neversleep/llama-3-lumimaid-70b",
          "neversleep/llama-3-lumimaid-8b",
          "neversleep/llama-3.1-lumimaid-70b",
          "neversleep/llama-3.1-lumimaid-8b",
          "neversleep/noromaid-20b",
          "---NOUSRESEARCH---",
          "nousresearch/hermes-2-pro-llama-3-8b",
          "nousresearch/hermes-3-llama-3.1-405b",
          "nousresearch/hermes-3-llama-3.1-70b",
          "nousresearch/nous-hermes-2-mixtral-8x7b-dpo",
          "nousresearch/nous-hermes-llama2-13b",
          "---OPENAI---",
          "openai/chatgpt-4o-latest",
          "openai/gpt-3.5-turbo",
          "openai/gpt-3.5-turbo-0125",
          "openai/gpt-3.5-turbo-0613",
          "openai/gpt-3.5-turbo-1106",
          "openai/gpt-3.5-turbo-16k",
          "openai/gpt-3.5-turbo-instruct",
          "openai/gpt-4",
          "openai/gpt-4-0314",
          "openai/gpt-4-1106-preview",
          "openai/gpt-4-32k",
          "openai/gpt-4-32k-0314",
          "openai/gpt-4-turbo",
          "openai/gpt-4-turbo-preview",
          "openai/gpt-4o",
          "openai/gpt-4o-2024-05-13",
          "openai/gpt-4o-2024-08-06",
          "openai/gpt-4o-2024-11-20",
          "openai/gpt-4o-mini",
          "openai/gpt-4o-mini-2024-07-18",
          "openai/o1",
          "openai/o1-mini",
          "openai/o1-mini-2024-09-12",
          "openai/o1-preview",
          "openai/o1-preview-2024-09-12",
          "---PERPLEXITY---",
          "perplexity/llama-3.1-sonar-huge-128k-online",
          "perplexity/llama-3.1-sonar-large-128k-chat",
          "perplexity/llama-3.1-sonar-large-128k-online",
          "perplexity/llama-3.1-sonar-small-128k-chat",
          "perplexity/llama-3.1-sonar-small-128k-online",
          "---QWEN---",
          "qwen/qvq-72b-preview",
          "qwen/qwen-2-72b-instruct",
          "qwen/qwen-2-7b-instruct",
          "qwen/qwen-2-vl-72b-instruct",
          "qwen/qwen-2-vl-7b-instruct",
          "qwen/qwen-2.5-72b-instruct",
          "qwen/qwen-2.5-7b-instruct",
          "qwen/qwen-2.5-coder-32b-instruct",
          "qwen/qwq-32b-preview",
          "---SAO10K---",
          "sao10k/l3-euryale-70b",
          "sao10k/l3-lunaris-8b",
          "sao10k/l3.1-70b-hanami-x1",
          "sao10k/l3.1-euryale-70b",
          "sao10k/l3.3-euryale-70b",
          "---X-AI---",
          "x-ai/grok-2-1212",
          "x-ai/grok-2-vision-1212",
          "x-ai/grok-beta",
          "x-ai/grok-vision-beta",
          "---OTHERS---",
          "01-ai/yi-large",
          "aetherwiing/mn-starcannon-12b",
          "alpindale/goliath-120b",
          "alpindale/magnum-72b",
          "anthracite-org/magnum-v2-72b",
          "anthracite-org/magnum-v4-72b",
          "cognitivecomputations/dolphin-mixtral-8x22b",
          "cognitivecomputations/dolphin-mixtral-8x7b",
          "databricks/dbrx-instruct",
          "gryphe/mythomax-l2-13b",
          "infermatic/mn-inferor-12b",
          "inflection/inflection-3-pi",
          "inflection/inflection-3-productivity",
          "jondurbin/airoboros-l2-70b",
          "mancer/weaver",
          "minimax/minimax-01",
          "nothingiisreal/mn-celeste-12b",
          "nvidia/llama-3.1-nemotron-70b-instruct",
          "openchat/openchat-7b",
          "pygmalionai/mythalion-13b",
          "raifle/sorcererlm-8x22b",
          "sophosympatheia/midnight-rose-70b",
          "teknium/openhermes-2.5-mistral-7b",
          "thedrummer/rocinante-12b",
          "thedrummer/unslopnemo-12b",
          "undi95/remm-slerp-l2-13b",
          "undi95/toppy-m-7b",
          "xwin-lm/xwin-lm-70b"
          ]
        fetch: false
      dropParams: ["stop"]
      titleConvo: true
      titleModel: "openai/gpt-4o-mini"
      summarize: false
      summaryModel: "openai/gpt-4o-mini"
      forcePrompt: false
      modelDisplayLabel: "OpenRouter"

    # Preplexity
    # Model list: https://docs.perplexity.ai/docs/model-cards
    - name: "Perplexity"
      apiKey: "${PERPLEXITY_API_KEY}"
      baseURL: "https://api.perplexity.ai/"
      models:
        default: [
          "llama-3.1-sonar-small-128k-chat",
          "llama-3.1-sonar-small-128k-online",
          "llama-3.1-sonar-large-128k-chat",
          "llama-3.1-sonar-large-128k-online",
          "llama-3.1-sonar-huge-128k-online",
          "llama-3.1-8b-instruct",
          "llama-3.1-70b-instruct"
          ]
        fetch: false # fetching list of models is not supported
      titleConvo: true
      titleModel: "llama-3.1-sonar-small-128k-chat"
      summarize: false
      summaryModel: "llama-3.1-sonar-small-128k-chat"
      forcePrompt: false
      dropParams: ["stop", "frequency_penalty"]
      modelDisplayLabel: "Perplexity"

    # SambaNova
    # https://cloud.sambanova.ai/apis
    - name: "SambaNova"
      apiKey: "${SAMBANOVA_API_KEY}"
      baseURL: "https://api.sambanova.ai/v1/"
      models:
        default: [
          "Meta-Llama-3.1-8B-Instruct",
          "Meta-Llama-3.1-70B-Instruct",
          "Meta-Llama-3.1-405B-Instruct",
          "Meta-Llama-3.2-1B-Instruct",
          "Meta-Llama-3.2-3B-Instruct",
          "Llama-3.2-11B-Vision-Instruct",
          "Llama-3.2-90B-Vision-Instruct",
          ]
        fetch: false
      titleConvo: true
      titleModel: "Meta-Llama-3.1-8B-Instruct"
      modelDisplayLabel: "SambaNova"
      iconURL: "https://global.discourse-cdn.com/sambanova/original/1X/f5ea7759d23daaad4f91a387079b8a8a71cae3f6.webp"

    # ShuttleAI API
    # Model list: https://shuttleai.com/models
    - name: "ShuttleAI"
      apiKey: "${SHUTTLEAI_API_KEY}"
      baseURL: "https://api.shuttleai.com/v1"
      models: 
        default: [
          "shuttleai/shuttle-3",
          "shuttleai/shuttle-3-mini",
          "shuttleai/s1",
          "shuttleai/s1-mini",
          "openai/o1-preview-2024-09-12",
          "openai/o1-mini-2024-09-12",
          "openai/gpt-4o-mini-2024-07-18",
          "openai/chatgpt-4o-latest",
          "openai/gpt-4o-2024-08-06",
          "openai/gpt-4o-2024-05-13",
          "openai/gpt-4-turbo-2024-04-09",
          "openai/gpt-4-0125-preview",
          "openai/gpt-4-1106-preview",
          "openai/gpt-4-0613",
          "openai/gpt-3.5-turbo-0125",
          "openai/gpt-3.5-turbo-1106",
          "anthropic/claude-3-5-sonnet-20240620",
          "anthropic/claude-3-opus-20240229",
          "anthropic/claude-3-haiku-20240307",
          "google/gemini-1.5-pro",
          "google/gemini-1.5-pro-exp-0827",
          "google/gemini-1.5-flash",
          "google/gemini-1.5-flash-exp-0827",
          "google/gemini-1.5-flash-8b-exp-0924",
          "meta-llama/meta-llama-3.2-90b-vision-instruct",
          "meta-llama/meta-llama-3.1-405b-instruct",
          "meta-llama/meta-llama-3.1-70b-instruct",
          "meta-llama/meta-llama-3.1-8b-instruct",
          "mattshumer/reflection-llama-3.1-70b",
          "perplexity/llama-3.1-sonar-large-128k-online",
          "perplexity/llama-3.1-sonar-small-128k-online",
          "perplexity/llama-3.1-sonar-large-128k-chat",
          "perplexity/llama-3.1-sonar-small-128k-chat",
          "mistralai/mistral-nemo-instruct-2407",
          "mistralai/codestral-2405",
          "alibaba-cloud/qwen-2.5-72b-instruct",
          "alibaba-cloud/qwen-2.5-coder-7b",
          "alibaba-cloud/qwen-2.5-math-72b",
          "cohere/command-r-plus-08-2024",
          "cohere/command-r-plus",
          "cohere/command-r-08-2024",
          "cohere/command-r"
          ]
        fetch: true
      titleConvo: true
      titleModel: "shuttle-2.5-mini"
      summarize: false
      summaryModel: "shuttle-2.5-mini"
      forcePrompt: false
      dropParams: ["user", "frequency_penalty", "presence_penalty", "repition_penalty"]
      modelDisplayLabel: "ShuttleAI"

    # together.ai
    # https://api.together.ai/settings/api-keys
    # Model list: https://docs.together.ai/docs/inference-models
    - name: "together.ai"
      apiKey: "${TOGETHERAI_API_KEY}"
      baseURL: "https://api.together.xyz"
      models:
        default: [
          "Gryphe/MythoMax-L2-13b",
          "Gryphe/MythoMax-L2-13b-Lite",
          "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO",
          "Qwen/QwQ-32B-Preview",
          "Qwen/Qwen2-72B-Instruct",
          "Qwen/Qwen2-VL-72B-Instruct",
          "Qwen/Qwen2.5-72B-Instruct-Turbo",
          "Qwen/Qwen2.5-7B-Instruct-Turbo",
          "Qwen/Qwen2.5-Coder-32B-Instruct",
          "databricks/dbrx-instruct",
          "deepseek-ai/DeepSeek-R1",
          "deepseek-ai/DeepSeek-V3",
          "deepseek-ai/deepseek-llm-67b-chat",
          "dev-vfs/Qwen2-VL-72B-Instruct",
          "devuser/test-lora-model-creation-1",
          "devuser/test-lora-model-creation-10",
          "devuser/test-lora-model-creation-2",
          "devuser/test-lora-model-creation-3",
          "devuser/test-lora-model-creation-4",
          "devuser/test-lora-model-creation-5",
          "devuser/test-lora-model-creation-6",
          "devuser/test-lora-model-creation-7",
          "devuser/test-lora-model-creation-8",
          "devuser/test-lora-model-creation-9",
          "google/gemma-2-27b-it",
          "google/gemma-2-9b-it",
          "google/gemma-2b-it",
          "jd/test-lora-model-creation-2",
          "jd/test-min-lora-model-creation-2",
          "justindriemeyer_tai/test-lora-model-creation-3",
          "justindriemeyer_tai/test-lora-model-creation-4",
          "justindriemeyer_tai/test-lora-model-creation-5",
          "justindriemeyer_tai/test-lora-model-creation-6",
          "justindriemeyer_tai/test-lora-model-creation-7",
          "llava-hf/llava-v1.6-mistral-7b-hf",
          "meta-llama/Llama-2-13b-chat-hf",
          "meta-llama/Llama-2-7b-chat-hf",
          "meta-llama/Llama-3-70b-chat-hf",
          "meta-llama/Llama-3-8b-chat-hf",
          "meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo",
          "meta-llama/Llama-3.2-3B-Instruct-Turbo",
          "meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo",
          "meta-llama/Llama-3.3-70B-Instruct-Turbo",
          "meta-llama/Llama-3.3-70B-Instruct-Turbo-Free",
          "meta-llama/Llama-Vision-Free",
          "meta-llama/Meta-Llama-3-70B-Instruct-Lite",
          "meta-llama/Meta-Llama-3-70B-Instruct-Turbo",
          "meta-llama/Meta-Llama-3-8B-Instruct-Lite",
          "meta-llama/Meta-Llama-3-8B-Instruct-Turbo",
          "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
          "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
          "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
          "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-128K",
          "microsoft/WizardLM-2-8x22B",
          "mistralai/Mistral-7B-Instruct-v0.1",
          "mistralai/Mistral-7B-Instruct-v0.2",
          "mistralai/Mistral-7B-Instruct-v0.3",
          "mistralai/Mixtral-8x22B-Instruct-v0.1",
          "mistralai/Mixtral-8x7B-Instruct-v0.1",
          "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF",
          "salesforce/xgen-9b-instruct",
          "scb10x/llama-3-typhoon-v1.5-8b-instruct",
          "scb10x/scb10x-llama3-typhoon-v1-5-8b-instruct",
          "scb10x/scb10x-llama3-typhoon-v1-5x-4f316",
          "togethercomputer/Llama-3-8b-chat-hf-int4",
          "togethercomputer/Llama-3-8b-chat-hf-int8",
          "upstage/SOLAR-10.7B-Instruct-v1.0",
          "vfs/Qwen2-VL-72B-Instruct"
          ]
        fetch: false
      titleConvo: true
      titleModel: "togethercomputer/llama-2-7b-chat"
      summarize: false
      summaryModel: "togethercomputer/llama-2-7b-chat"
      forcePrompt: false
      modelDisplayLabel: "together.ai"

    # Unify
    # Model list: https://unify.ai/chat
    - name: "Unify"
      apiKey: "${UNIFY_API_KEY}"
      baseURL: "https://api.unify.ai/v0/"
      models:
        default: [
          "router@q:1|c:2.12e-01|t:5.00e-04|i:2.78e-04",
          "chatgpt-4o-latest@openai",
          "gpt-3.5-turbo@openai",
          "gpt-4-turbo@openai",
          "gpt-4@openai",
          "gpt-4o-2024-05-13@openai",
          "gpt-4o-2024-08-06@openai",
          "gpt-4o-2024-11-20@openai",
          "gpt-4o-mini@openai",
          "gpt-4o@openai",
          "o1-mini@openai",
          "o1-preview@openai",
          "o1@openai",
          "claude-3-haiku@anthropic",
          "claude-3-opus@anthropic",
          "claude-3-sonnet@anthropic",
          "claude-3.5-haiku@anthropic",
          "claude-3.5-sonnet-20240620@anthropic",
          "claude-3.5-sonnet@anthropic",
          "claude-3-haiku@aws-bedrock",
          "claude-3-opus@aws-bedrock",
          "claude-3-sonnet@aws-bedrock",
          "claude-3.5-haiku@aws-bedrock",
          "claude-3.5-sonnet-20240620@aws-bedrock",
          "claude-3.5-sonnet@aws-bedrock",
          "command-r-plus@aws-bedrock",
          "llama-3-70b-chat@aws-bedrock",
          "llama-3-8b-chat@aws-bedrock",
          "llama-3.1-405b-chat@aws-bedrock",
          "llama-3.1-70b-chat@aws-bedrock",
          "llama-3.1-8b-chat@aws-bedrock",
          "llama-3.2-1b-chat@aws-bedrock",
          "llama-3.2-3b-chat@aws-bedrock",
          "llama-3.3-70b-chat@aws-bedrock",
          "mistral-7b-instruct-v0.2@aws-bedrock",
          "mistral-large@aws-bedrock",
          "mixtral-8x7b-instruct-v0.1@aws-bedrock",
          "claude-3-haiku@vertex-ai",
          "claude-3-opus@vertex-ai",
          "claude-3-sonnet@vertex-ai",
          "claude-3.5-haiku@vertex-ai",
          "claude-3.5-sonnet-20240620@vertex-ai",
          "claude-3.5-sonnet@vertex-ai",
          "gemini-1.0-pro-001@vertex-ai",
          "gemini-1.0-pro-002@vertex-ai",
          "gemini-1.0-pro@vertex-ai",
          "gemini-1.5-flash-001@vertex-ai",
          "gemini-1.5-flash-002@vertex-ai",
          "gemini-1.5-flash@vertex-ai",
          "gemini-1.5-pro-001@vertex-ai",
          "gemini-1.5-pro-002@vertex-ai",
          "gemini-1.5-pro@vertex-ai",
          "gemini-2.0-flash@vertex-ai",
          "llama-3.1-405b-chat@vertex-ai",
          "llama-3.1-70b-chat@vertex-ai",
          "llama-3.1-8b-chat@vertex-ai",
          "llama-3.2-11b-chat@vertex-ai",
          "llama-3.2-90b-chat@vertex-ai",
          "mistral-large@vertex-ai",
          "mistral-nemo@vertex-ai",
          "deepseek-r1@deepseek",
          "deepseek-v3@deepseek",
          "deepseek-r1@fireworks-ai",
          "deepseek-v3@fireworks-ai",
          "llama-3-70b-chat@fireworks-ai",
          "llama-3-8b-chat@fireworks-ai",
          "llama-3.1-405b-chat@fireworks-ai",
          "llama-3.1-70b-chat@fireworks-ai",
          "llama-3.1-8b-chat@fireworks-ai",
          "llama-3.2-11b-chat@fireworks-ai",
          "llama-3.2-3b-chat@fireworks-ai",
          "llama-3.2-90b-chat@fireworks-ai",
          "llama-3.3-70b-chat@fireworks-ai",
          "mixtral-8x22b-instruct-v0.1@fireworks-ai",
          "mixtral-8x7b-instruct-v0.1@fireworks-ai",
          "qwen-2.5-72b-instruct@fireworks-ai",
          "qwen-2.5-coder-32b-instruct@fireworks-ai",
          "qwen-qwq-32b-preview@fireworks-ai",
          "deepseek-r1@together-ai",
          "deepseek-v3@together-ai",
          "gemma-2-27b-it@together-ai",
          "gemma-2-9b-it@together-ai",
          "llama-3-70b-chat@together-ai",
          "llama-3-8b-chat@together-ai",
          "llama-3.1-405b-chat@together-ai",
          "llama-3.1-70b-chat@together-ai",
          "llama-3.1-8b-chat@together-ai",
          "llama-3.2-11b-chat@together-ai",
          "llama-3.2-3b-chat@together-ai",
          "llama-3.2-90b-chat@together-ai",
          "llama-3.3-70b-chat@together-ai",
          "mistral-7b-instruct-v0.3@together-ai",
          "mixtral-8x22b-instruct-v0.1@together-ai",
          "mixtral-8x7b-instruct-v0.1@together-ai",
          "qwen-2-72b-instruct@together-ai",
          "qwen-2.5-72b-instruct@together-ai",
          "qwen-2.5-7b-instruct@together-ai",
          "qwen-2.5-coder-32b-instruct@together-ai",
          "qwen-qwq-32b-preview@together-ai",
          "deepseek-v3@deepinfra",
          "gemma-2-27b-it@deepinfra",
          "gemma-2-9b-it@deepinfra",
          "llama-3-70b-chat@deepinfra",
          "llama-3-8b-chat@deepinfra",
          "llama-3.1-405b-chat@deepinfra",
          "llama-3.1-70b-chat@deepinfra",
          "llama-3.1-8b-chat@deepinfra",
          "llama-3.1-nemotron-70b-chat@deepinfra",
          "llama-3.2-11b-chat@deepinfra",
          "llama-3.2-1b-chat@deepinfra",
          "llama-3.2-3b-chat@deepinfra",
          "llama-3.2-90b-chat@deepinfra",
          "llama-3.3-70b-chat@deepinfra",
          "mistral-7b-instruct-v0.3@deepinfra",
          "mistral-nemo@deepinfra",
          "mixtral-8x7b-instruct-v0.1@deepinfra",
          "qwen-2.5-72b-instruct@deepinfra",
          "qwen-2.5-coder-32b-instruct@deepinfra",
          "qwen-qwq-32b-preview@deepinfra",
          "gemma-2-9b-it@groq",
          "llama-3-70b-chat@groq",
          "llama-3-8b-chat@groq",
          "llama-3.1-8b-chat@groq",
          "llama-3.2-11b-chat@groq",
          "llama-3.2-1b-chat@groq",
          "llama-3.2-3b-chat@groq",
          "llama-3.2-90b-chat@groq",
          "llama-3.3-70b-chat@groq",
          "mixtral-8x7b-instruct-v0.1@groq",
          "gemma-2-9b-it@lepton-ai",
          "llama-3-70b-chat@lepton-ai",
          "llama-3-8b-chat@lepton-ai",
          "llama-3.1-70b-chat@lepton-ai",
          "llama-3.1-8b-chat@lepton-ai",
          "llama-3.2-1b-chat@lepton-ai",
          "llama-3.2-3b-chat@lepton-ai",
          "llama-3.3-70b-chat@lepton-ai",
          "mistral-7b-instruct-v0.3@lepton-ai",
          "mistral-nemo@lepton-ai",
          "mixtral-8x7b-instruct-v0.1@lepton-ai",
          "grok-2-vision@xai",
          "grok-2@xai",
          "llama-3-70b-chat@replicate",
          "llama-3-8b-chat@replicate",
          "llama-3.1-405b-chat@replicate",
          "mixtral-8x7b-instruct-v0.1@replicate",
          "ministral-3b@mistral-ai",
          "ministral-8b@mistral-ai",
          "mistral-7b-instruct-v0.3@mistral-ai",
          "mistral-large@mistral-ai",
          "mistral-nemo@mistral-ai",
          "mistral-small@mistral-ai",
          "mixtral-8x22b-instruct-v0.1@mistral-ai",
          "mixtral-8x7b-instruct-v0.1@mistral-ai",
          ]
        fetch: false
      titleConvo: true
      titleModel: "gpt-4o-mini@openai"
      dropParams: ["stop", "user", "frequency_penalty", "presence_penalty"]

    - name: "xai"
      apiKey: "${XAI_API_KEY}"
      baseURL: "https://api.x.ai/v1"
      models:
        default: ["grok-beta"]
        fetch: false
      titleConvo: true
      titleMethod: "completion"
      titleModel: "grok-beta"
      summarize: false
      summaryModel: "grok-beta"
      forcePrompt: false
      modelDisplayLabel: "Grok"
