version: 1.1.5

cache: true
fileStrategy: "firebase"

interface:
  privacyPolicy:
    externalUrl: 'https://librechat.ai/privacy-policy'
    openNewTab: true
  termsOfService:
    externalUrl: 'https://librechat.ai/tos'
    openNewTab: true

registration:
  socialLogins: ["discord", "facebook", "github", "google", "openid"]

endpoints:
  custom:
    # Anyscale
    # # Model list: https://console.anyscale.com/v2/playground
    - name: "Anyscale"
      apiKey: "user_provided"
      baseURL: "https://api.endpoints.anyscale.com/v1"
      models:
        default: [
          "google/gemma-7b-it",
          "llava-hf/llava-v1.6-mistral-7b-hf",
          "meta-llama/Meta-Llama-3-70B-Instruct",
          "meta-llama/Meta-Llama-3-8B-Instruct",
          "mistralai/Mistral-7B-Instruct-v0.1",
          "mistralai/Mixtral-8x22B-Instruct-v0.1",
          "mistralai/Mixtral-8x7B-Instruct-v0.1",
          "mlabonne/NeuralHermes-2.5-Mistral-7B",
          ]
        fetch: false
      titleConvo: true
      titleModel: "meta-llama/Meta-Llama-3-8B-Instruct"
      summarize: false
      summaryModel: "meta-llama/Meta-Llama-3-8B-Instruct"
      forcePrompt: false
      modelDisplayLabel: "Anyscale"

    # APIpie
    # Script to fetch models: https://github.com/LibreChat-AI/librechat-config-yaml/blob/main/scripts/apipie.py
    - name: "APIpie"
      apiKey: "user_provided"
      baseURL: "https://apipie.ai/v1/"
      models:
        default: [  
          "GPT-JT-Moderation-6B",
          "LLaMA-2-7B-32K",
          "Llama-2-13b-chat-hf",
          "Llama-2-13b-hf",
          "Llama-2-70b-chat-hf",
          "Llama-2-70b-hf",
          "Llama-2-7B-32K-Instruct",
          "Llama-2-7b-chat-hf",
          "Llama-2-7b-hf",
          "Meta-Llama-3-70B-Instruct",
          "Meta-Llama-3-8B-Instruct",
          "Mistral-7B-Instruct-v0.1",
          "Mistral-7B-Instruct-v0.2",
          "Mistral-7B-OpenOrca",
          "Mixtral-8x22B-Instruct-v0.1",
          "Mixtral-8x22B-v0.1",
          "Mixtral-8x7B-Instruct-v0.1",
          "Mixtral-8x7B-v0.1",
          "MythoMax-L2-13b",
          "NexusRaven-V2-13B",
          "Nous-Hermes-2-Mixtral-8x7B-DPO",
          "Nous-Hermes-2-Mixtral-8x7B-SFT",
          "Nous-Hermes-Llama2-13b",
          "Nous-Hermes-llama-2-7b",
          "Phi-3-mini-4k-instruct",
          "ReMM-SLERP-L2-13B",
          "RedPajama-INCITE-7B-Base",
          "RedPajama-INCITE-7B-Chat",
          "RedPajama-INCITE-Chat-3B-v1",
          "TinyLlama-1.1B-Chat-v1.0",
          "Toppy-M-7B",
          "WizardLM-2-7B",
          "WizardLM-2-8x22B",
          "Yi-34B-Chat",
          "airoboros-70b",
          "airoboros-l2-70b",
          "alpaca-7b",
          "babbage-002",
          "chat-bison",
          "chronos-hermes-13b",
          "chronos-hermes-13b-v2",
          "claude-1",
          "claude-1.2",
          "claude-2",
          "claude-2.0",
          "claude-2.1",
          "claude-3-5-sonnet",
          "claude-3-haiku",
          "claude-3-opus",
          "claude-3-sonnet",
          "claude-instant-1",
          "claude-instant-1.0",
          "claude-instant-1.1",
          "claude-instant-1.2",
          "command",
          "command-light",
          "command-light-nightly",
          "command-light-text-v14",
          "command-nightly",
          "command-r",
          "command-r-plus",
          "command-r-plus-v1",
          "command-r-v1",
          "command-text-v14",
          "davinci-002",
          "dbrx-instruct",
          "deepseek-chat",
          "dolphin-2.5-mixtral-8x7b",
          "dolphin-2.6-mixtral-8x7b",
          "dolphin-llama-3-70b",
          "dolphin-mixtral-8x22b",
          "dolphin-mixtral-8x7b",
          "eagle-7b",
          "fimbulvetr-11b-v2",
          "firellava-13b",
          "gemini-1.5-flash",
          "gemini-1.5-pro",
          "gemini-flash-1.5",
          "gemini-pro",
          "gemini-pro-1.5",
          "gemini-pro-vision",
          "gemma-1.1-7b-it",
          "gemma-2-27b-it",
          "gemma-2-9b-it",
          "gemma-7b-it",
          "goliath-120b",
          "gpt-3.5-turbo",
          "gpt-3.5-turbo-0125",
          "gpt-3.5-turbo-0301",
          "gpt-3.5-turbo-0613",
          "gpt-3.5-turbo-1106",
          "gpt-3.5-turbo-16k",
          "gpt-3.5-turbo-16k-0613",
          "gpt-3.5-turbo-instruct",
          "gpt-3.5-turbo-instruct-0914",
          "gpt-4",
          "gpt-4-0125-preview",
          "gpt-4-0314",
          "gpt-4-0613",
          "gpt-4-1106-preview",
          "gpt-4-1106-vision-preview",
          "gpt-4-32k",
          "gpt-4-32k-0314",
          "gpt-4-turbo",
          "gpt-4-turbo-2024-04-09",
          "gpt-4-turbo-preview",
          "gpt-4-vision-preview",
          "gpt-4o",
          "gpt-4o-2024-05-13",
          "gpt-4o-mini",
          "gpt-4o-mini-2024-07-18",
          "hermes-2-pro-llama-3-8b",
          "hermes-2-theta-llama-3-8b",
          "j2-grande-instruct",
          "j2-jumbo-instruct",
          "j2-mid",
          "j2-mid-v1",
          "j2-ultra",
          "j2-ultra-v1",
          "jamba-instruct",
          "jamba-instruct-v1",
          "l3-euryale-70b",
          "l3-stheno-8b",
          "large-latest",
          "llama-2-13b-chat",
          "llama-2-70b-chat",
          "llama-3-70b",
          "llama-3-70b-instruct",
          "llama-3-8b",
          "llama-3-8b-instruct",
          "llama-3-lumimaid-70b",
          "llama-3-lumimaid-8b",
          "llama-3-sonar-large-32k-chat",
          "llama-3-sonar-large-32k-online",
          "llama-3-sonar-small-32k-chat",
          "llama-3-sonar-small-32k-online",
          "llama-3.1-405b-instruct",
          "llama-3.1-70b-instruct",
          "llama-3.1-8b-instruct",
          "llama-3.1-sonar-large-128k-chat",
          "llama-3.1-sonar-large-128k-online",
          "llama-3.1-sonar-small-128k-chat",
          "llama-3.1-sonar-small-128k-online",
          "llama-guard-2-8b",
          "llama2-13b-chat-v1",
          "llama2-70b-chat-v1",
          "llama3-70b-instruct-v1",
          "llama3-70b-instruct-v1:0",
          "llama3-8b-instruct-v1",
          "llama3-8b-instruct-v1:0",
          "llava-1.5-7b-hf",
          "lzlv-70b-fp16-hf",
          "lzlv_70b_fp16_hf",
          "magnum-72b",
          "medium",
          "midnight-rose-70b",
          "mistral-7b-instruct",
          "mistral-7b-instruct-v0",
          "mistral-7b-instruct-v0.1",
          "mistral-7b-instruct-v0.2",
          "mistral-7b-instruct-v0.3",
          "mistral-large",
          "mistral-medium",
          "mistral-nemo",
          "mistral-small",
          "mistral-small-2402-v1",
          "mistral-tiny",
          "mixtral-8x22b",
          "mixtral-8x22b-instruct",
          "mixtral-8x7b",
          "mixtral-8x7b-instruct",
          "mixtral-8x7b-instruct-v0",
          "mythalion-13b",
          "mythomax-l2-13b",
          "mythomist-7b",
          "noromaid-20b",
          "nous-capybara-7b",
          "nous-hermes-2-mistral-7b-dpo",
          "nous-hermes-2-mixtral-8x7b-dpo",
          "nous-hermes-2-mixtral-8x7b-sft",
          "nous-hermes-2-vision-7b",
          "nous-hermes-llama2-13b",
          "nous-hermes-yi-34b",
          "olmo-7b-instruct",
          "olympus-premier-v1",
          "openchat-3.5-1210",
          "openchat-7b",
          "openchat-8b",
          "openchat_3.5",
          "openhermes-2-mistral-7b",
          "openhermes-2.5-mistral-7b",
          "palm-2-chat-bison",
          "palm-2-chat-bison-32k",
          "phi-2",
          "phi-3-medium-128k-instruct",
          "phi-3-medium-4k-instruct",
          "phi-3-mini-128k-instruct",
          "pplx-70b-online",
          "pplx-7b-chat",
          "psyfighter-13b-2",
          "qwen-110b-chat",
          "qwen-14b-chat",
          "qwen-2-72b-instruct",
          "qwen-2-7b-instruct",
          "qwen-32b-chat",
          "qwen-4b-chat",
          "qwen-72b-chat",
          "qwen-7b-chat",
          "remm-slerp-l2-13b",
          "small",
          "snowflake-arctic-instruct",
          "soliloquy-l3",
          "sonar-medium-online",
          "sonar-small-chat",
          "sonar-small-online",
          "stripedhyena-hessian-7b",
          "stripedhyena-nous-7b",
          "text-babbage-002",
          "text-bison",
          "text-davinci-002",
          "tiny",
          "titan-text-express-v1",
          "titan-text-lite-v1",
          "titan-text-premier-v1",
          "titan-tg1-large",
          "toppy-m-7b",
          "vicuna-13b-v1.5",
          "vicuna-7b-v1.5",
          "weaver",
          "wizardlm-2-7b",
          "wizardlm-2-8x22b",
          "xwin-lm-70b",
          "yi-34b",
          "yi-34b-chat",
          "yi-6b",
          "yi-large",
          "zephyr-7b-beta",
          "zephyr-orpo-141b-A35b-v0.1"
          ]
        fetch: false
      titleConvo: true
      titleModel: "claude-3-haiku"
      summarize: false
      summaryModel: "claude-3-haiku"
      modelDisplayLabel: "APIpie"

    # cohere
    # Model list: https://dashboard.cohere.com/playground/chat
    - name: "cohere"
      apiKey: "user_provided"
      baseURL: "https://api.cohere.ai/v1"
      models:
        default: [
          "c4ai-aya-23-35b",
          "c4ai-aya-23-8b",
          "command",
          "command-light",
          "command-light-nightly",
          "command-nightly",
          "command-r",
          "command-r-plus",
          ]
        fetch: false
      modelDisplayLabel: "cohere"
      titleModel: "command"
      dropParams: ["stop", "user", "frequency_penalty", "presence_penalty", "temperature", "top_p"]

    # DEEPNIGHT
    # https://github.com/brahmai-research/aiforcause
    # Model list: https://aiforcause.deepnight.tech/models
    - name: "DEEPNIGHT"
      apiKey: "sk-free1234"
      baseURL: "https://aiforcause.deepnight.tech/openai/"
      models:
        default: [
          "gpt-35-turbo",
          "gpt-35-turbo-16k",
          "gpt-4-turbo"
          ]
        fetch: false
      titleConvo: true
      titleModel: "gpt-35-turbo"
      summarize: false
      summaryModel: "gpt-35-turbo"
      forcePrompt: false
      modelDisplayLabel: "DEEPNIGHT"
      addParams:
        stream: True
      iconURL: "https://raw.githubusercontent.com/LibreChat-AI/librechat-config-yaml/main/icons/DEEPNIGHT.png"
      
    # Fireworks.ai
    # Models: https://fireworks.ai/models?show=Serverless
    - name: "Fireworks"
      apiKey: "user_provided"
      baseURL: "https://api.fireworks.ai/inference/v1"
      models:
        default: [
          "accounts/fireworks/models/devashisht-test-v2",
          "accounts/fireworks/models/dt-fc-rc-v1",
          "accounts/fireworks/models/firefunction-v1",
          "accounts/fireworks/models/firefunction-v2",
          "accounts/fireworks/models/firellava-13b",
          "accounts/devashisht-72fdad/models/function-calling-v11",
          "accounts/fireworks/models/fw-function-call-34b-v0",
          "accounts/stability/models/japanese-stablelm-instruct-beta-70b",
          "accounts/stability/models/japanese-stablelm-instruct-gamma-7b",
          "accounts/fireworks/models/japanese-stable-vlm",
          "accounts/fireworks/models/gemma2-9b-it",
          "accounts/fireworks/models/llama-v3p1-405b-instruct",
          "accounts/fireworks/models/llama-v3p1-70b-instruct",
          "accounts/fireworks/models/llama-v3p1-8b-instruct",
          "accounts/fireworks/models/llama-v3-70b-instruct",
          "accounts/fireworks/models/llama-v3-70b-instruct-hf",
          "accounts/fireworks/models/llama-v3-8b-hf",
          "accounts/fireworks/models/llama-v3-8b-instruct",
          "accounts/fireworks/models/llama-v3-8b-instruct-hf",
          "accounts/fireworks/models/llama-v2-13b-chat",
          "accounts/fireworks/models/llama-v2-13b-code-instruct",
          "accounts/fireworks/models/llama-v2-34b-code-instruct",
          "accounts/fireworks/models/llama-v2-70b-chat",
          "accounts/fireworks/models/llama-v2-70b-code-instruct",
          "accounts/fireworks/models/llama-v2-7b-chat",
          "accounts/fireworks/models/deepseek-coder-v2-instruct",
          "accounts/fireworks/models/deepseek-coder-v2-lite-instruct",
          "accounts/fireworks/models/llava-v15-13b-fireworks",
          "accounts/fireworks/models/mistral-7b-instruct-4k",
          "accounts/dev-e24710/models/mistral-spellbound-format",
          "accounts/fireworks/models/mixtral-8x22b-instruct",
          "accounts/fireworks/models/mixtral-8x7b-instruct",
          "accounts/fireworks/models/mixtral-8x7b-instruct-hf",
          "accounts/fireworks/models/new-mixtral-chat",
          "accounts/fireworks/models/qwen-14b-chat",
          "accounts/fireworks/models/qwen-1-8b-chat",
          "accounts/fireworks/models/qwen-72b-chat",
          "accounts/stability/models/stablelm-zephyr-3b",
          "accounts/fireworks/models/yi-34b-200k-capybara",
          ]
        fetch: false
      titleConvo: true
      titleModel: "accounts/fireworks/models/llama-v2-7b-chat"
      summarize: false
      summaryModel: "accounts/fireworks/models/llama-v2-7b-chat"
      forcePrompt: false
      modelDisplayLabel: "Fireworks"
      dropParams: ["user"]
      
    # groq
    # Model list: https://console.groq.com/settings/limits
    - name: "groq"
      apiKey: "user_provided"
      baseURL: "https://api.groq.com/openai/v1/"
      models:
        default: [
          "llama-3.1-405b-reasoning",
          "llama-3.1-70b-versatile",
          "llama-3.1-8b-instant",
          "llama3-groq-70b-8192-tool-use-preview",
          "llama3-groq-8b-8192-tool-use-preview",
          "llama3-70b-8192",
          "llama3-8b-8192",
          "mixtral-8x7b-32768",
          "gemma-7b-it",
          "gemma2-9b-it"
          ]
        fetch: false
      titleConvo: true
      titleModel: "mixtral-8x7b-32768"
      modelDisplayLabel: "groq"
      
    # Mistral AI API
    # Model list: https://docs.mistral.ai/getting-started/models/
    - name: "Mistral"
      apiKey: "user_provided"
      baseURL: "https://api.mistral.ai/v1"
      models: 
        default: [
          "mistral-tiny",
          "mistral-small",
          "mistral-medium",
          "mistral-large-latest",
          "open-mistral-nemo",
          "open-mistral-7b",
          "open-mixtral-8x7b",
          "open-mixtral-8x22b",
          "open-codestral-mamba"
          ]
        fetch: false
      titleConvo: true
      titleMethod: "completion"
      titleModel: "mistral-tiny"
      summarize: false
      summaryModel: "mistral-tiny"
      forcePrompt: false
      modelDisplayLabel: "Mistral"
      dropParams: ["stop", "user", "frequency_penalty", "presence_penalty"]

    # OpenRouter.ai
    # Model list: https://openrouter.ai/models
    # Script to fetch models: https://github.com/LibreChat-AI/librechat-config-yaml/blob/main/scripts/openrouter.py
    - name: "OpenRouter"
      apiKey: "user_provided"
      baseURL: "https://openrouter.ai/api/v1"
      models:
        default: [
          "openrouter/auto",
          "---FREE---",
          "google/gemma-2-9b-it:free",
          "google/gemma-7b-it:free",
          "gryphe/mythomist-7b:free",
          "huggingfaceh4/zephyr-7b-beta:free",
          "meta-llama/llama-3-8b-instruct:free",
          "meta-llama/llama-3.1-8b-instruct:free",
          "microsoft/phi-3-medium-128k-instruct:free",
          "microsoft/phi-3-mini-128k-instruct:free",
          "mistralai/mistral-7b-instruct:free",
          "nousresearch/nous-capybara-7b:free",
          "openchat/openchat-7b:free",
          "qwen/qwen-2-7b-instruct:free",
          "undi95/toppy-m-7b:free",
          "---NITRO---",
          "google/gemma-7b-it:nitro",
          "gryphe/mythomax-l2-13b:nitro",
          "meta-llama/llama-3-70b-instruct:nitro",
          "meta-llama/llama-3-8b-instruct:nitro",
          "mistralai/mistral-7b-instruct:nitro",
          "mistralai/mixtral-8x7b-instruct:nitro",
          "undi95/toppy-m-7b:nitro",
          "---BETA---",
          "anthropic/claude-2.0:beta",
          "anthropic/claude-2.1:beta",
          "anthropic/claude-2:beta",
          "anthropic/claude-3-haiku:beta",
          "anthropic/claude-3-opus:beta",
          "anthropic/claude-3-sonnet:beta",
          "anthropic/claude-3.5-sonnet:beta",
          "anthropic/claude-instant-1:beta",
          "---EXTENDED---",
          "gryphe/mythomax-l2-13b:extended",
          "meta-llama/llama-3-8b-instruct:extended",
          "neversleep/llama-3-lumimaid-8b:extended",
          "undi95/remm-slerp-l2-13b:extended",
          "---01-AI---",
          "01-ai/yi-34b",
          "01-ai/yi-34b-chat",
          "01-ai/yi-6b",
          "---ANTHROPIC---",
          "anthropic/claude-1",
          "anthropic/claude-1.2",
          "anthropic/claude-2",
          "anthropic/claude-2.0",
          "anthropic/claude-2.1",
          "anthropic/claude-3-haiku",
          "anthropic/claude-3-opus",
          "anthropic/claude-3-sonnet",
          "anthropic/claude-3.5-sonnet",
          "anthropic/claude-instant-1",
          "anthropic/claude-instant-1.0",
          "anthropic/claude-instant-1.1",
          "---COGNITIVECOMPUTATIONS---",
          "cognitivecomputations/dolphin-llama-3-70b",
          "cognitivecomputations/dolphin-mixtral-8x22b",
          "cognitivecomputations/dolphin-mixtral-8x7b",
          "---COHERE---",
          "cohere/command",
          "cohere/command-r",
          "cohere/command-r-plus",
          "---GOOGLE---",
          "google/gemini-flash-1.5",
          "google/gemini-pro",
          "google/gemini-pro-1.5",
          "google/gemini-pro-vision",
          "google/gemma-2-27b-it",
          "google/gemma-2-9b-it",
          "google/gemma-7b-it",
          "google/palm-2-chat-bison",
          "google/palm-2-chat-bison-32k",
          "google/palm-2-codechat-bison",
          "google/palm-2-codechat-bison-32k",
          "---META-LLAMA---",
          "meta-llama/codellama-34b-instruct",
          "meta-llama/codellama-70b-instruct",
          "meta-llama/llama-2-13b-chat",
          "meta-llama/llama-2-70b-chat",
          "meta-llama/llama-3-70b",
          "meta-llama/llama-3-70b-instruct",
          "meta-llama/llama-3-8b",
          "meta-llama/llama-3-8b-instruct",
          "meta-llama/llama-3.1-405b-instruct",
          "meta-llama/llama-3.1-70b-instruct",
          "meta-llama/llama-3.1-8b-instruct",
          "meta-llama/llama-guard-2-8b",
          "---MICROSOFT---",
          "microsoft/phi-3-medium-128k-instruct",
          "microsoft/phi-3-medium-4k-instruct",
          "microsoft/phi-3-mini-128k-instruct",
          "microsoft/wizardlm-2-7b",
          "microsoft/wizardlm-2-8x22b",
          "---MISTRALAI---",
          "mistralai/codestral-mamba",
          "mistralai/mistral-7b-instruct",
          "mistralai/mistral-7b-instruct-v0.1",
          "mistralai/mistral-7b-instruct-v0.2",
          "mistralai/mistral-7b-instruct-v0.3",
          "mistralai/mistral-large",
          "mistralai/mistral-medium",
          "mistralai/mistral-nemo",
          "mistralai/mistral-small",
          "mistralai/mistral-tiny",
          "mistralai/mixtral-8x22b",
          "mistralai/mixtral-8x22b-instruct",
          "mistralai/mixtral-8x7b",
          "mistralai/mixtral-8x7b-instruct",
          "---NEVERSLEEP---",
          "neversleep/llama-3-lumimaid-70b",
          "neversleep/llama-3-lumimaid-8b",
          "neversleep/noromaid-20b",
          "---NOUSRESEARCH---",
          "nousresearch/hermes-2-pro-llama-3-8b",
          "nousresearch/hermes-2-theta-llama-3-8b",
          "nousresearch/nous-capybara-7b",
          "nousresearch/nous-hermes-2-mistral-7b-dpo",
          "nousresearch/nous-hermes-2-mixtral-8x7b-dpo",
          "nousresearch/nous-hermes-2-mixtral-8x7b-sft",
          "nousresearch/nous-hermes-llama2-13b",
          "nousresearch/nous-hermes-yi-34b",
          "---OPENAI---",
          "openai/gpt-3.5-turbo",
          "openai/gpt-3.5-turbo-0125",
          "openai/gpt-3.5-turbo-0301",
          "openai/gpt-3.5-turbo-0613",
          "openai/gpt-3.5-turbo-1106",
          "openai/gpt-3.5-turbo-16k",
          "openai/gpt-3.5-turbo-instruct",
          "openai/gpt-4",
          "openai/gpt-4-0314",
          "openai/gpt-4-1106-preview",
          "openai/gpt-4-32k",
          "openai/gpt-4-32k-0314",
          "openai/gpt-4-turbo",
          "openai/gpt-4-turbo-preview",
          "openai/gpt-4-vision-preview",
          "openai/gpt-4o",
          "openai/gpt-4o-2024-05-13",
          "openai/gpt-4o-mini",
          "openai/gpt-4o-mini-2024-07-18",
          "---PERPLEXITY---",
          "perplexity/llama-3.1-sonar-large-128k-chat",
          "perplexity/llama-3.1-sonar-large-128k-online",
          "perplexity/llama-3.1-sonar-small-128k-chat",
          "perplexity/llama-3.1-sonar-small-128k-online",
          "perplexity/llama-3.1-sonar-huge-128k-online",
          "---QWEN---",
          "qwen/qwen-110b-chat",
          "qwen/qwen-14b-chat",
          "qwen/qwen-2-72b-instruct",
          "qwen/qwen-2-7b-instruct",
          "qwen/qwen-32b-chat",
          "qwen/qwen-4b-chat",
          "qwen/qwen-72b-chat",
          "qwen/qwen-7b-chat",
          "---SAO10K---",
          "sao10k/fimbulvetr-11b-v2",
          "sao10k/l3-euryale-70b",
          "sao10k/l3-stheno-8b",
          "---OTHERS---",
          "ai21/jamba-instruct",
          "allenai/olmo-7b-instruct",
          "alpindale/goliath-120b",
          "alpindale/magnum-72b",
          "austism/chronos-hermes-13b",
          "databricks/dbrx-instruct",
          "deepseek/deepseek-chat",
          "deepseek/deepseek-coder",
          "fireworks/firellava-13b",
          "gryphe/mythomax-l2-13b",
          "gryphe/mythomist-7b",
          "jondurbin/airoboros-l2-70b",
          "lizpreciatior/lzlv-70b-fp16-hf",
          "lynn/soliloquy-l3",
          "mancer/weaver",
          "open-orca/mistral-7b-openorca",
          "openchat/openchat-7b",
          "openchat/openchat-8b",
          "openrouter/flavor-of-the-week",
          "phind/phind-codellama-34b",
          "pygmalionai/mythalion-13b",
          "recursal/eagle-7b",
          "recursal/rwkv-5-3b-ai-town",
          "rwkv/rwkv-5-world-3b",
          "snowflake/snowflake-arctic-instruct",
          "sophosympatheia/midnight-rose-70b",
          "teknium/openhermes-2-mistral-7b",
          "teknium/openhermes-2.5-mistral-7b",
          "togethercomputer/stripedhyena-hessian-7b",
          "togethercomputer/stripedhyena-nous-7b",
          "undi95/remm-slerp-l2-13b",
          "undi95/toppy-m-7b",
          "xwin-lm/xwin-lm-70b"
          ]
        fetch: false
      dropParams: ["stop"]
      titleConvo: true
      titleModel: "gpt-3.5-turbo"
      summarize: false
      summaryModel: "gpt-3.5-turbo"
      forcePrompt: false
      modelDisplayLabel: "OpenRouter"

    # Preplexity
    # Model list: https://docs.perplexity.ai/docs/model-cards
    - name: "Perplexity"
      apiKey: "user_provided"
      baseURL: "https://api.perplexity.ai/"
      models:
        default: [
          "llama-3.1-sonar-small-128k-chat",
          "llama-3.1-sonar-small-128k-online",
          "llama-3.1-sonar-large-128k-chat",
          "llama-3.1-sonar-large-128k-online",
          "llama-3.1-sonar-huge-128k-online",
          "llama-3.1-8b-instruct",
          "llama-3.1-70b-instruct"
          ]
        fetch: false # fetching list of models is not supported
      titleConvo: true
      titleModel: "llama-3.1-sonar-small-128k-chat"
      summarize: false
      summaryModel: "llama-3.1-sonar-small-128k-chat"
      forcePrompt: false
      dropParams: ["stop", "frequency_penalty"]
      modelDisplayLabel: "Perplexity"

    # ShuttleAI API
    # Model list: https://shuttleai.app/models
    - name: "ShuttleAI"
      apiKey: "user_provided"
      baseURL: "https://api.shuttleai.app/v1"
      models: 
        default: [
          "shuttle-2-turbo",
          "shuttle-turbo",
          "gpt-4o-2024-05-13",
          "gpt-4o",
          "im-also-a-good-gpt2-chatbot",
          "gpt-4-turbo-2024-04-09",
          "gpt-4-turbo",
          "gpt-4-0125-preview",
          "gpt-4-turbo-preview",
          "gpt-4-1106-preview",
          "gpt-4-1106-vision-preview",
          "gpt-4-vision-preview",
          "gpt-4-0613",
          "gpt-4",
          "gpt-4-bing",
          "gpt-4-turbo-bing",
          "gpt-4-32k-0613",
          "gpt-4-32k",
          "gpt-3.5-turbo-0125",
          "gpt-3.5-turbo",
          "gpt-3.5-turbo-1106",
          "claude-3-opus-20240229",
          "claude-3-opus",
          "claude-3-sonnet-20240229",
          "claude-3-sonnet",
          "claude-3-haiku-20240307",
          "claude-3-haiku",
          "claude-2.1",
          "claude-2.0",
          "claude-2",
          "claude-instant-1.2",
          "claude-instant-1.1",
          "claude-instant-1.0",
          "claude-instant",
          "meta-llama-3-70b-instruct",
          "llama-3-70b-instruct",
          "meta-llama-3-8b-instruct",
          "llama-3-8b-instruct",
          "llama-3-sonar-large-32k-online",
          "llama-3-sonar-small-32k-online",
          "llama-3-sonar-large-32k-chat",
          "llama-3-sonar-small-32k-chat",
          "blackbox",
          "blackbox-code",
          "wizardlm-2-8x22b",
          "wizardlm-2-70b",
          "dolphin-2.6-mixtral-8x7b",
          "dolphin-mixtral-8x7b",
          "mistral-large",
          "mistral-next",
          "mistral-medium",
          "mistral-small",
          "mistral-tiny",
          "mixtral-8x7b-instruct-v0.1",
          "mixtral-8x7b-instruct",
          "mixtral-8x22b-instruct-v0.1",
          "mixtral-8x22b-instruct",
          "mistral-7b-instruct-v0.2",
          "mistral-7b-instruct-2",
          "mistral-7b-instruct-v0.1",
          "mistral-7b-instruct",
          "nous-hermes-2-mixtral-8x7b",
          "gemini-1.5-pro-latest",
          "gemini-1.5-pro",
          "gemini-1.0-pro-latest",
          "gemini-1.0-pro",
          "gemini-pro",
          "gemini-1.0-pro-vision",
          "gemini-pro-vision",
          "lzlv-70b",
          "figgs-rp",
          "cinematika-7b"
          ]
        fetch: true
      titleConvo: true
      titleMethod: "completion"
      titleModel: "shuttle-2-turbo"
      summarize: false
      summaryModel: "shuttle-2-turbo"
      forcePrompt: false
      dropParams: ["user", "frequency_penalty", "presence_penalty", "repetition_penalty"]
      modelDisplayLabel: "ShuttleAI"

    # together.ai
    # Model list: https://docs.together.ai/docs/inference-models
    - name: "together.ai"
      apiKey: "user_provided"
      baseURL: "https://api.together.xyz"
      models:
        default: [
          "zero-one-ai/Yi-34B-Chat",
          "Austism/chronos-hermes-13b",
          "DiscoResearch/DiscoLM-mixtral-8x7b-v2",
          "Gryphe/MythoMax-L2-13b",
          "lmsys/vicuna-13b-v1.5",
          "lmsys/vicuna-7b-v1.5",
          "lmsys/vicuna-13b-v1.5-16k",
          "codellama/CodeLlama-13b-Instruct-hf",
          "codellama/CodeLlama-34b-Instruct-hf",
          "codellama/CodeLlama-70b-Instruct-hf",
          "codellama/CodeLlama-7b-Instruct-hf",
          "togethercomputer/llama-2-13b-chat",
          "togethercomputer/llama-2-70b-chat",
          "togethercomputer/llama-2-7b-chat",
          "NousResearch/Nous-Capybara-7B-V1p9",
          "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO",
          "NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT",
          "NousResearch/Nous-Hermes-Llama2-70b",
          "NousResearch/Nous-Hermes-llama-2-7b",
          "NousResearch/Nous-Hermes-Llama2-13b",
          "NousResearch/Nous-Hermes-2-Yi-34B",
          "openchat/openchat-3.5-1210",
          "Open-Orca/Mistral-7B-OpenOrca",
          "togethercomputer/Qwen-7B-Chat",
          "snorkelai/Snorkel-Mistral-PairRM-DPO",
          "togethercomputer/alpaca-7b",
          "togethercomputer/falcon-40b-instruct",
          "togethercomputer/falcon-7b-instruct",
          "togethercomputer/GPT-NeoXT-Chat-Base-20B",
          "togethercomputer/Llama-2-7B-32K-Instruct",
          "togethercomputer/Pythia-Chat-Base-7B-v0.16",
          "togethercomputer/RedPajama-INCITE-Chat-3B-v1",
          "togethercomputer/RedPajama-INCITE-7B-Chat",
          "togethercomputer/StripedHyena-Nous-7B",
          "Undi95/ReMM-SLERP-L2-13B",
          "Undi95/Toppy-M-7B",
          "WizardLM/WizardLM-13B-V1.2",
          "garage-bAInd/Platypus2-70B-instruct",
          "mistralai/Mistral-7B-Instruct-v0.1",
          "mistralai/Mistral-7B-Instruct-v0.2",
          "mistralai/Mixtral-8x7B-Instruct-v0.1",
          "teknium/OpenHermes-2-Mistral-7B",
          "teknium/OpenHermes-2p5-Mistral-7B",
          "upstage/SOLAR-10.7B-Instruct-v1.0"
          ]
        fetch: false
      titleConvo: true
      titleModel: "openchat/openchat-3.5-1210"
      summarize: false
      summaryModel: "openchat/openchat-3.5-1210"
      forcePrompt: false
      modelDisplayLabel: "together.ai"

    # Unify
    # Model list: https://unify.ai/chat
    - name: "Unify"
      apiKey: "user_provided"
      baseURL: "https://api.unify.ai/v0/"
      models:
        default: [
          "router@q:1|c:2.12e-01|t:5.00e-04|i:2.78e-04",
          "gpt-3.5-turbo@openai",
          "gpt-4o@openai",
          "gpt-4-turbo@openai",
          "gpt-4@openai",
          "claude-3-haiku@anthropic",
          "claude-3-sonnet@anthropic",
          "claude-3-opus@anthropic",
          "claude-3.5-sonnet@anthropic",
          "mistral-small@mistral-ai",
          "mistral-medium@mistral-ai",
          "mistral-large@mistral-ai",
          "mixtral-8x22b-instruct-v0.1@fireworks-ai",
          "mistral-7b-instruct-v0.2@replicate",
          "mixtral-8x7b-instruct-v0.1@replicate",
          "mistral-7b-instruct-v0.1@fireworks-ai",
          "gemma-2b-it@together-ai",
          "gemma-7b-it@fireworks-ai",
          "llama-2-7b-chat@replicate",
          "llama-2-13b-chat@fireworks-ai",
          "llama-2-70b-chat@octoai",
          "llama-3-8b-chat@fireworks-ai",
          "llama-3-70b-chat@fireworks-ai",
          "codellama-7b-instruct@octoai",
          "codellama-13b-instruct@octoai",
          "codellama-34b-instruct@octoai",
          "deepseek-coder-33b-instruct@together-ai",
          "pplx-7b-chat@perplexity-ai",
          "pplx-70b-chat@perplexity-ai",
          "yi-34b-chat@deepinfra",
          ]
        fetch: false
      titleConvo: true
      titleModel: "claude-3-haiku@anthropic"
      dropParams: ["stop", "user", "frequency_penalty", "presence_penalty"]
      iconURL: "https://raw.githubusercontent.com/LibreChat-AI/librechat-config-yaml/main/icons/Unify.webp"


# REVERSE PROXY

    # ConvoAI
    - name: "ConvoAI"
      apiKey: "user_provided"
      baseURL: "https://api.convoai.tech/v1/"
      models:
        default: [
          "gpt-3.5-turbo",
          "gpt-3.5-turbo-1106",
          "gpt-3.5-turbo-0125",
          "gpt-3.5-turbo-16k",
          "gpt-4",
          "gpt-4-0613",
          "gpt-4-1106-preview",
          "gpt-4-0125-preview",
          "gpt-4-vision-preview",
          "gpt-4-turbo-2024-04-09",
          "convoai-pro",
          "mixtral-8x22b",
          "gpt-3.5-turbo-16k-0613",
          "gpt-3.5-turbo-0613",
          "gpt-4-32k",
          "gpt-4-1106-vision-preview",
          "claude-2",
          "claude-3-haiku",
          "claude-3-sonnet",
          "claude-3-opus",
          "claude-instant-1.2",
          "gemma-2b",
          "gemma-2b-it",
          "gemma-7b",
          "gemma-7b-it",
          "gemini-1.0-pro-001",
          "gemini-pro",
          "gemini-1.0-pro",
          "gemini-1.0-pro-latest",
          "gemini-1.5-pro",
          "gemini-1.5-pro-latest",
          "gemini-pro-vision",
          "mistral-7b",
          "mixtral-8x7b-Instruct-v0.1",
          "mistral-7b-instruct-v0.1",
          "mistral-7b-instruct-v0.2",
          "mixtral-8x7b",
          "dolphin-mixtral-8x7b",
          "mistral-tiny",
          "mistral-small",
          "mistral-medium",
          "mistral-large",
          "llama2-7b",
          "llama2-70b",
          "llama2-13b",
          "code-llama-7b",
          "code-llama-70b-instruct",
          "code-llama-13b",
          "code-llama-34b",
          "code-llama-34b-instruct",
          "openchat-3.5",
          "yi-34b-chat",
          "yi-34b-200k",
          "command-r-plus",
          "command-r-plus-4bit",
          "aya-101",
          "dbrx-instruct",
          ]
        fetch: false
      titleConvo: true
      titleModel: "gpt-3.5-turbo"
      summarize: false
      summaryModel: "gpt-3.5-turbo"
      forcePrompt: false
      modelDisplayLabel: "ConvoAI"
      iconURL: "https://raw.githubusercontent.com/LibreChat-AI/librechat-config-yaml/main/icons/ConvoAI.png"

    # FreeGPT-4
    - name: "FreeGPT-4"
      apiKey: "user_provided"
      baseURL: "https://api.freegpt4.tech/v1/"
      models:
        default: [
          "gpt-3.5-turbo",
          "gpt-3.5-turbo-1106",
          "gpt-3.5-turbo-0125",
          "gpt-3.5-turbo-16k",
          "gpt-4",
          "gpt-4-1106-preview",
          "gpt-4-0125-preview",
          "claude",
          "gemini-pro"
          ]
        fetch: false
      titleConvo: true
      titleModel: "gpt-3.5-turbo"
      summarize: false
      summaryModel: "gpt-3.5-turbo"
      forcePrompt: false
      modelDisplayLabel: "FreeGPT-4"
      iconURL: "https://raw.githubusercontent.com/LibreChat-AI/librechat-config-yaml/main/icons/FreeGPT-4.png"
 
    # Mandrill
    - name: "Mandrill"
      apiKey: "user_provided"
      baseURL: "https://api.mandrillai.tech/v1"
      models:
        default: [
          "gpt-4o",
          "gpt-4-turbo",
          "gpt-4-0125-preview",
          "gpt-4-1106-preview",
          "gpt-4",
          "gpt-3.5-turbo",
          "gpt-3.5-turbo-1106",
          "gpt-3.5-turbo-0613",
          "gpt-3.5-turbo-0301",
          "claude-3-opus",
          "gemini-pro",
          "gemini-pro-vision"
          ]
        fetch: false
      titleConvo: true
      titleModel: "gpt-3.5-turbo"
      summarize: false
      summaryModel: "gpt-3.5-turbo"
      forcePrompt: false
      modelDisplayLabel: "Mandrill"
      iconURL: "https://raw.githubusercontent.com/LibreChat-AI/librechat-config-yaml/main/icons/Mandrill.png"

    # NagaAI
    - name: "NagaAI"
      apiKey: "user_provided"
      baseURL: "https://api.naga.ac/v1"
      models:
        default: [
          "gpt-4",
          "gpt-4-vision-preview",
          "gpt-4-turbo-preview",
          "gpt-4-0125-preview",
          "gpt-4-1106-preview",
          "gpt-4-0613",
          "mistral-large",
          "mistral-large-2402",
          "mistral-next",
          "mistral-small",
          "mistral-small-2402",
          "gpt-3.5-turbo",
          "gpt-3.5-turbo-0125",
          "gpt-3.5-turbo-1106",
          "gpt-3.5-turbo-0613",
          "claude-3-opus",
          "claude-3-opus-20240229",
          "claude-3-sonnet",
          "claude-3-sonnet-20240229",
          "claude-3-haiku",
          "claude-3-haiku-20240307",
          "claude-2.1",
          "claude-instant",
          "gemini-pro",
          "gemini-pro-vision",
          "llama-2-70b-chat",
          "llama-2-13b-chat",
          "llama-2-7b-chat",
          "mistral-7b",
          "mixtral-8x7b"
          ]
        fetch: false
      titleConvo: true
      titleModel: "gpt-3.5-turbo"
      summarize: false
      summaryModel: "gpt-3.5-turbo"
      forcePrompt: false
      modelDisplayLabel: "NagaAI"
      iconURL: "https://raw.githubusercontent.com/LibreChat-AI/librechat-config-yaml/main/icons/NagaAI.png"
      
    # Pawan
    - name: "Pawan"
      apiKey: "user_provided"
      baseURL: "https://api.pawan.krd/pai-001-rp/v1"
      models:
        default: [
          "pai-001-rp"
          ]
        fetch: false
      titleConvo: true
      titleModel: "pai-001-rp"
      summarize: false
      summaryModel: "pai-001-rp"
      forcePrompt: false
      modelDisplayLabel: "Pawan"
      iconURL: "https://raw.githubusercontent.com/LibreChat-AI/librechat-config-yaml/main/icons/Pawan.png"

    # Pawan light
    - name: "Pawan light"
      apiKey: "user_provided"
      baseURL: "https://api.pawan.krd/pai-001-light-rp/v1"
      models:
        default: [
          "pai-001-light-rp"
          ]
        fetch: false
      titleConvo: true
      titleModel: "pai-001-light-rp"
      summarize: false
      summaryModel: "pai-001-light-rp"
      forcePrompt: false
      modelDisplayLabel: "Pawan light"
      iconURL: "https://raw.githubusercontent.com/LibreChat-AI/librechat-config-yaml/main/icons/Pawan.png"

    #Shard
    - name: "Shard"
      apiKey: "user_provided"
      baseURL: "https://api.shard-ai.xyz/v1/"
      models:
        default: [
          'gpt-3.5-turbo-0301',
          'gpt-3.5-turbo-0613',
          'gpt-3.5-turbo',
          'gpt-3.5-turbo-1106',
          'gpt-3.5-turbo-0125',
          'gpt-3.5-turbo-instruct',
          'gpt-3.5-turbo-instruct-0914',
          'gpt-3.5-turbo-16k',
          'gpt-4-0613',
          'gpt-4',
          'gpt-4-turbo',
          'gpt-4-turbo-2024-04-09',
          'gpt-4-1106-preview',
          'gpt-4-0125-preview',
          'gpt-4-turbo-preview',
          'gpt-4-vision-preview',
          'command-r',
          'command-r-plus',
          'command-light-nightly',
          'command',
          'command-light',
          'c4ai-aya',
          'claude',
          'claude-1.2',
          'claude-2',
          'claude-2.1',
          'claude-3-haiku',
          'claude-3-sonnet',
          'claude-3-opus',
          'claude-instant-v1',
          'claude-instant-v1-100k',
          'palm-2',
          'dbrx-instruct',
          'gemini-pro',
          'gemini-1.5-pro',
          'mixtral-8x7b-instruct',
          'mixtral-8x7b',
          'mixtral-8x22b',
          'mixtral-8x22b-finetuned',
          'zephyr-8x22b',
          'zephyr-7b',
          'mistral-tiny',
          'mistral-small',
          'mistral-medium', 
          'mistral-large',
          'mistral-next', 
          'mistral-7b-instruct',
          'yi-34b',
          'gemma-2b',
          'gemma-7b', 'gemma-1.1-7b',
          'llamaguard-7b',
          'llama-2-7b',
          'llama-2-13b',
          'llama-2-70b',
          'llama-3-8b',
          'llama-3-70b',
          'openchat-3.5',
          'phind-codellama-34b',
          'llava-1.5',
          'llava-1.6-34b',
          'llava-1.6-7b',
          'lzlv-70b', 
          'airoboros-70b',
          'airoboros-70b-gpt4',
          'cinematika-7b',
          'toppy-7b',
          'codellama-7b-instruct',
          'codellama-13b-instruct',
          'codellama-34b-instruct', 
          'codellama-70b-instruct', 
          'dolphine-mixtral', 
          'pi', 'mythomax-l2-13b',
          'nous-capybara-7b', 
          'sonar-small-chat', 
          'sonar-medium-chat',
          'sonar-small-online', 
          'sonar-medium-online', 
          'perplexity-related',
          'hermes-2', 
          'hermes-2-pro', 
          'qwen-1.5-32b-chat'
          ]
        fetch: false
      titleConvo: true
      titleModel: "gpt-3.5-turbo"
      modelDisplayLabel: "Shard"
      iconURL: "https://raw.githubusercontent.com/LibreChat-AI/librechat-config-yaml/main/icons/shard.png"

    # Zukijourney
    - name: "Zukijourney"
      apiKey: "user_provided"
      baseURL: "https://zukijourney.xyzbot.net/unf/"
      models:
        default: [
          "gpt-3.5-turbo",
          "gpt-3.5-turbo-1106",
          "gpt-3.5-turbo-0125",
          "gpt-3.5-turbo-instruct",
          "gpt-3.5-turbo-16k",
          "gpt-4",
          "gpt-4o",
          "gpt-4-32k",
          "gpt-4-1106-preview",
          "gpt-4-0125-preview",
          "gpt-4-vision-preview",
          "claude",
          "claude-2",
          "claude-2.1",
          "claude-instant-v1",
          "claude-instant-v1-100k",
          "claude-3-opus",
          "claude-3-sonnet",
          "claude-3.5-sonnet",
          "pplx-70b-online",
          "palm-2",
          "bard",
          "gemini-pro",
          "gemini-pro-vision",
          "mixtral-8x7b",
          "mixtral-8x7b-instruct",
          "mistral-tiny",
          "mistral-small",
          "mistral-medium",
          "mistral-7b-instruct",
          "codellama-7b-instruct",
          "llama-2-7b",
          "llama-2-70b-chat",
          "mythomax-l2-13b-8k",
          "sheep-duck-llama",
          "goliath-120b",
          "nous-llama",
          "yi-34b",
          "openchat",
          "solar10-7b",
          "pi"
          ]
        fetch: true
      titleConvo: true
      titleModel: "gpt-3.5-turbo"
      summarize: false
      summaryModel: "gpt-3.5-turbo"
      forcePrompt: false
      dropParams: ["stream"]
      iconURL: "https://raw.githubusercontent.com/LibreChat-AI/librechat-config-yaml/main/icons/zuki.png"
